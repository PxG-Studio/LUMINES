name: WISSIL Unified QA Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Unit & Integration Tests (Vitest)
  unit-tests:
    name: Unit Tests (Vitest)
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run unit tests
        run: npm run test:unit
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        if: always()
        with:
          files: ./coverage/coverage-final.json
          flags: unit
          name: unit-tests

  integration-tests:
    name: Integration Tests (Vitest)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run integration tests
        run: npm run test:integration

  # E2E Tests (Playwright)
  e2e-tests:
    name: E2E Tests (Playwright)
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Install Playwright browsers
        run: npx playwright install --with-deps
      
      - name: Build Storybook
        run: npm run build-storybook
        continue-on-error: false
      
      - name: Start Storybook server
        run: npx serve storybook-static -l 6006 &
        env:
          PORT: 6006
      
      - name: Run E2E tests
        run: npm run test:e2e
        env:
          BASE_URL: http://localhost:6006
          CI: true
      
      - name: Upload Playwright report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-report
          path: playwright-report/
          retention-days: 30
      
      - name: Upload Playwright traces
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-traces
          path: test-results/
          retention-days: 30

  # Visual Regression Tests (Chromatic + Percy)
  visual-regression-chromatic:
    name: Visual Regression (Chromatic)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Build Storybook
        run: npm run build-storybook
      
      - name: Publish to Chromatic
        uses: chromaui/action@v1
        with:
          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}
          autoAcceptChanges: false
          onlyChanged: true
          exitZeroOnChanges: false
          turboSnap: true
          buildScriptName: build-storybook

  visual-regression-percy:
    name: Visual Regression (Percy)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Build Storybook
        run: npm run build-storybook
      
      - name: Run Percy snapshots
        run: npm run percy:storybook
        env:
          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}
        continue-on-error: false
      
      - name: Upload Storybook build artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: storybook-static-percy
          path: storybook-static/
          retention-days: 7

  # Performance Tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Install Playwright browsers
        run: npx playwright install --with-deps
      
      - name: Run performance tests
        run: npm run test:perf
      
      - name: Upload performance report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-report
          path: performance-report/
          retention-days: 30

  # Unified QA Summary
  qa-summary:
    name: QA Summary
    runs-on: ubuntu-latest
    needs: [
      unit-tests,
      integration-tests,
      e2e-tests,
      visual-regression-chromatic,
      visual-regression-percy,
      performance-tests
    ]
    if: always()
    steps:
      - name: Generate QA Summary
        run: |
          echo "## ğŸ§ª WISSIL Unified QA Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests (Vitest) | ${{ needs.unit-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests (Vitest) | ${{ needs.integration-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| E2E Tests (Playwright) | ${{ needs.e2e-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Visual Regression (Chromatic) | ${{ needs.visual-regression-chromatic.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Visual Regression (Percy) | ${{ needs.visual-regression-percy.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance Tests | ${{ needs.performance-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Visual Regression Strategy" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "WISSIL uses **dual visual regression testing** for comprehensive coverage:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Chromatic**: Primary visual regression with tight Storybook integration, TurboSnap optimization" >> $GITHUB_STEP_SUMMARY
          echo "- **Percy**: Cross-browser testing, responsive snapshots across multiple viewports" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Both tools run in parallel to minimize CI time while maximizing coverage." >> $GITHUB_STEP_SUMMARY
      
      - name: Comment PR with results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const allPassed = 
              '${{ needs.unit-tests.result }}' === 'success' &&
              '${{ needs.integration-tests.result }}' === 'success' &&
              '${{ needs.e2e-tests.result }}' === 'success' &&
              '${{ needs.visual-regression-chromatic.result }}' === 'success' &&
              '${{ needs.visual-regression-percy.result }}' === 'success' &&
              '${{ needs.performance-tests.result }}' === 'success';
            
            const icon = allPassed ? 'âœ…' : 'âŒ';
            const status = allPassed ? 'All tests passed!' : 'Some tests failed';
            
            const body = `## ğŸ§ª WISSIL Unified QA Pipeline
            
            Status: ${icon} ${status}
            
            ### Results
            
            | Test Suite | Status |
            |------------|--------|
            | Unit Tests | ${{ needs.unit-tests.result === 'success' ? 'âœ…' : 'âŒ' }} |
            | Integration Tests | ${{ needs.integration-tests.result === 'success' ? 'âœ…' : 'âŒ' }} |
            | E2E Tests | ${{ needs.e2e-tests.result === 'success' ? 'âœ…' : 'âŒ' }} |
            | Visual Regression (Chromatic) | ${{ needs.visual-regression-chromatic.result === 'success' ? 'âœ…' : 'âŒ' }} |
            | Visual Regression (Percy) | ${{ needs.visual-regression-percy.result === 'success' ? 'âœ…' : 'âŒ' }} |
            | Performance Tests | ${{ needs.performance-tests.result === 'success' ? 'âœ…' : 'âŒ' }} |
            
            **View detailed results:** [Workflow Run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

