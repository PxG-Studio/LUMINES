# â­ WISSIL QA DASHBOARD

**Complete QA Management System for Notion & Linear**

*Last updated: December 2024*

---

## ğŸ“˜ Overview

This dashboard provides a complete QA management system structured for **Notion** and **Linear**, enabling comprehensive test tracking, regression management, performance monitoring, and release gating.

**Modeled after:**
- âœ… Figma QA dashboards
- âœ… StackBlitz engineering QA
- âœ… Unity Editor QA workflows
- âœ… VS Code Web quality gates

---

# â­ 1. MASTER QUEUE â€” "WISSIL QA Board"

**Type:** Kanban Board  
**Purpose:** Central issue tracking for all QA activities

### Board Columns

```
Backlog â†’ Ready â†’ In Progress â†’ Blocked â†’ Review â†’ Done
```

### Issue Fields

| Field | Type | Description | Options |
|-------|------|-------------|---------|
| **Title** | Text | Short issue title | - |
| **QA Category** | Select | Primary category | Slate, Ignis, Canvas, Collab, Spark, C#, Runtime, Templates, AI, Visual, Performance |
| **Subsystem** | Select | WISSIL subsystem | Landing, Slate, Ignition, Spark, Ignis, Waypoint |
| **Severity** | Select | Priority level | P0, P1, P2, P3 |
| **Type** | Select | Issue type | Bug, Visual Regression, Performance, Spec Gap, Enhancement |
| **Status** | Board Column | Current state | Backlog, Ready, In Progress, Blocked, Review, Done |
| **Assigned To** | Person | QA or developer | - |
| **Repro Steps** | Multi-line | Steps to reproduce | - |
| **Environment** | Multi-select | Test environment | Chrome, Safari, Firefox, WebGL, Unity Editor |
| **Test Case ID** | Relation | Links to test cases | â†’ Test Cases Database |
| **Commit / PR** | Text | Git commit/PR link | - |
| **Video / Screenshot** | Attachment | Visual evidence | - |
| **Storybook Story** | Text | Path to story | e.g., `src/stories/ignis/BlueprintEditor.stories.tsx` |
| **Created** | Date | Creation date | - |
| **Updated** | Date | Last update | - |
| **Resolved** | Date | Resolution date | - |

---

# â­ 2. TEST CASE DATABASE â€” "WISSIL Test Cases"

**Type:** Database  
**Purpose:** Comprehensive test case registry

### Database Fields

| Field | Type | Description | Example |
|-------|------|-------------|---------|
| **Test Case ID** | Text (Unique) | Unique identifier | `IGNIS-CANVAS-011` |
| **Title** | Text | Test case name | "Node drag updates position correctly" |
| **Area** | Select | Test area | Slate, Ignis, Spark, Templates, Collab, Runtime, C# |
| **Feature** | Select | Feature tested | NodeRenderer, Canvas, WireRenderer, TemplateLoader, HotReload |
| **Steps** | Multi-line | Test steps | 1. Open blueprint editor<br>2. Add Print node<br>3. Drag node to position (200, 300)<br>4. Verify position updated |
| **Expected Result** | Text | Pass criteria | Node position equals { x: 200, y: 300 } |
| **Automated?** | Checkbox | Is test automated | â˜‘ Yes / â˜ No |
| **Automated Suite** | Select | Test suite type | Unit, Integration, E2E, Visual, Perf |
| **Test File Path** | Text | Test file location | `tests/e2e/ignis/blueprint-editor.spec.ts` |
| **Playwright Script** | Code | Test code snippet | - |
| **Status** | Select | Test status | Ready, Needs Review, Automated, Deprecated |
| **Last Run** | Date | Last execution date | - |
| **Last Result** | Select | Last result | Pass, Fail, Skipped |
| **Related Issues** | Relation | Linked issues | â†’ QA Board |

### Sample Test Cases

| Test Case ID | Title | Area | Automated? | Status |
|--------------|-------|------|------------|--------|
| `IGNIS-CANVAS-001` | Canvas pan with mouse drag | Ignis | â˜‘ Yes | Automated |
| `IGNIS-CANVAS-002` | Canvas zoom with wheel | Ignis | â˜‘ Yes | Automated |
| `SLATE-TOKEN-001` | Color tokens render correctly | Slate | â˜‘ Yes | Automated |
| `COLLAB-SYNC-001` | Node movement syncs between users | Collab | â˜‘ Yes | Automated |
| `SPARK-TEMP-001` | Template loads valid graph | Spark | â˜ No | Ready |

---

# â­ 3. QA CYCLE ORGANIZER â€” "WISSIL QA Sprints"

**Type:** Database  
**Purpose:** Organized QA cycles for systematic testing

### Database Fields

| Field | Type | Description |
|-------|------|-------------|
| **Cycle Name** | Text | Cycle identifier | "Cycle 01 â€” Foundation" |
| **Duration** | Date Range | Start and end dates | - |
| **Scope** | Multi-line | What's being tested | - |
| **Exit Criteria** | Multi-line | Completion criteria | - |
| **Pass/Fail** | Select | Cycle result | Pass, Fail, In Progress |
| **Issues Found** | Relation | Related issues | â†’ QA Board |
| **Coverage (%)** | Number | Manual test coverage | 0-100 |
| **Automated Coverage (%)** | Number | Automated test coverage | 0-100 |
| **Test Cases** | Relation | Included test cases | â†’ Test Cases Database |
| **Owner** | Person | Cycle lead | - |

### Predefined Cycles

| Cycle | Name | Duration | Scope | Status |
|-------|------|----------|-------|--------|
| **Cycle 01** | Foundation (Slate / Node UI) | 2 weeks | Slate tokens, NodeRenderer, basic UI | ğŸ”„ |
| **Cycle 02** | Canvas / Wires | 2 weeks | Canvas interactions, wire rendering | ğŸ”„ |
| **Cycle 03** | Interpreter / Execution | 2 weeks | BPInterpreter, graph execution | ğŸ”„ |
| **Cycle 04** | Spark Templates | 1 week | Template loading, validation | ğŸ”„ |
| **Cycle 05** | Ignition Hot Reload | 1 week | Hot reload, C# generation | ğŸ”„ |
| **Cycle 06** | Collab Layer | 2 weeks | Multi-user editing, sync | ğŸ”„ |
| **Cycle 07** | Storybook Regression | 1 week | Visual regression, Chromatic | ğŸ”„ |
| **Cycle 08** | Performance & Load | 1 week | FPS, load times, memory | ğŸ”„ |
| **Cycle 09** | WebGL Integration | 2 weeks | Unity bridge, runtime | ğŸ”„ |
| **Cycle 10** | AI/LUNA QA | 2 weeks | Graph generation, suggestions | ğŸ”„ |

---

# â­ 4. COVERAGE TRACKER â€” "Automation Coverage Report"

**Type:** Database  
**Purpose:** Track test automation coverage across all areas

### Database Fields

| Field | Type | Description |
|-------|------|-------------|
| **Area** | Select | Test area | Slate, Ignis, Spark, Collab, C#, Runtime |
| **Unit Test Coverage** | Number | Percentage | 0-100 |
| **Integration Test Coverage** | Number | Percentage | 0-100 |
| **E2E Coverage** | Number | Percentage | 0-100 |
| **Visual Regression Coverage** | Number | Percentage | 0-100 |
| **Performance Tests** | Number | Percentage | 0-100 |
| **Combined Coverage** | Formula | Average of all coverage types | - |
| **Risk Level** | Select | Coverage risk | High, Medium, Low |
| **Last Updated** | Date | Last coverage update | - |

### Coverage Formula

```
Combined Coverage = (Unit + Integration + E2E + Visual) / 4
```

### Sample Coverage Data

| Area | Unit | Integration | E2E | Visual | Combined | Risk |
|------|------|-------------|-----|--------|----------|------|
| Slate | 85% | 70% | 60% | 100% | 79% | Low |
| Ignis | 80% | 75% | 70% | 100% | 81% | Low |
| Spark | 70% | 60% | 50% | 90% | 68% | Medium |
| Collab | 60% | 50% | 40% | - | 50% | High |
| C# Generation | 75% | 65% | 55% | - | 65% | Medium |
| Runtime | 80% | 70% | 60% | - | 70% | Medium |

---

# â­ 5. REGRESSION GRID â€” "WISSIL Regression Matrix"

**Type:** Table  
**Purpose:** Track breakage by subsystem when merging features

### Matrix Table

| Feature | Slate | Ignis | Canvas | Collab | Spark | Runtime | UnityWebGL | AI | Notes |
|---------|-------|-------|--------|--------|-------|---------|------------|-----|-------|
| **NodeRenderer** | âœ” | âœ” | âœ” | â€“ | â€“ | â€“ | â€“ | â€“ | Core component |
| **WireRenderer** | â€“ | âœ” | âœ” | â€“ | â€“ | â€“ | â€“ | â€“ | Canvas-dependent |
| **BPGraphCanvas** | â€“ | âœ” | âœ” | â€“ | â€“ | â€“ | â€“ | â€“ | Main canvas |
| **Blueprint Interpreter** | â€“ | âœ” | â€“ | â€“ | â€“ | âœ” | âœ” | â€“ | Execution layer |
| **Canvas Dragging** | â€“ | âœ” | âœ” | â€“ | â€“ | â€“ | â€“ | â€“ | User interaction |
| **Template Loader** | â€“ | â€“ | â€“ | â€“ | âœ” | â€“ | â€“ | â€“ | Spark-specific |
| **Hot Reload** | â€“ | â€“ | â€“ | â€“ | â€“ | âœ” | âœ” | â€“ | Runtime feature |
| **Collab Multi-User** | â€“ | â€“ | â€“ | âœ” | â€“ | â€“ | â€“ | â€“ | Collaboration |
| **LUNA Graph Generation** | â€“ | âœ” | â€“ | â€“ | â€“ | â€“ | â€“ | âœ” | AI feature |
| **C# Code Generation** | â€“ | âœ” | â€“ | â€“ | â€“ | âœ” | âœ” | â€“ | Build feature |
| **Prefab Editor** | â€“ | âœ” | â€“ | â€“ | â€“ | â€“ | âœ” | â€“ | Unity tool |
| **Scene Graph** | â€“ | âœ” | â€“ | â€“ | â€“ | â€“ | âœ” | â€“ | Unity tool |
| **Audio Mixer** | â€“ | âœ” | â€“ | â€“ | â€“ | â€“ | âœ” | â€“ | Unity tool |
| **UI Canvas Editor** | â€“ | âœ” | â€“ | â€“ | â€“ | â€“ | âœ” | â€“ | Unity tool |

**Legend:**
- âœ” = Must test when feature changes
- â€“ = Does not apply

---

# â­ 6. VISUAL REGRESSION â€” "Chromatic Dashboard"

**Type:** Database  
**Purpose:** Track visual regression test status

### Database Fields

| Field | Type | Description |
|-------|------|-------------|
| **Story** | Text | Storybook story path | - |
| **Status** | Select | Test status | Pass, Fail, Needs Review |
| **Threshold** | Number | Diff threshold | 0.01, 0.05, 0.1 |
| **Last Run** | Date | Last Chromatic run | - |
| **Last Diff** | Number | Last diff percentage | - |
| **Screenshot** | Attachment | Latest snapshot | - |
| **Changes** | Multi-line | Recent changes | - |
| **Approved By** | Person | Visual approver | - |

### Sample Visual Regression Data

| Story | Status | Threshold | Last Diff | Viewport |
|-------|--------|-----------|-----------|----------|
| NodeRenderer Default | âœ… Pass | 0.01 | 0.002% | Desktop |
| NodeRenderer Selected | âœ… Pass | 0.01 | 0.001% | Desktop |
| WireRenderer Curved | âœ… Pass | 0.01 | 0.003% | Desktop |
| BPGraphCanvas Empty | âœ… Pass | 0.05 | 0.01% | Desktop |
| Full BlueprintEditor | âœ… Pass | 0.1 | 0.05% | Desktop |
| NodePalette Search | âœ… Pass | 0.05 | 0.02% | Desktop |

---

# â­ 7. PERFORMANCE BENCHMARK â€” "WISSIL Performance"

**Type:** Database  
**Purpose:** Track performance metrics and benchmarks

### Database Fields

| Field | Type | Description |
|-------|------|-------------|
| **Metric** | Text | Performance metric name | - |
| **Target** | Number | Target value | - |
| **Current** | Number | Current value | - |
| **Status** | Select | Pass/Fail | âœ… OK, âŒ FAIL |
| **Unit** | Select | Measurement unit | FPS, ms, MB, % |
| **Test File** | Text | Test file path | - |
| **Last Run** | Date | Last benchmark run | - |
| **Trend** | Select | Performance trend | Improving, Stable, Degrading |
| **Playwright Trace** | Attachment | Performance trace | - |
| **Notes** | Multi-line | Additional notes | - |

### Performance Metrics Table

| Metric | Target | Current | Status | Unit | Trend |
|--------|--------|---------|--------|------|-------|
| **Canvas Drag FPS** | 60 | 58 | âš ï¸ Warning | FPS | Stable |
| **Zoom FPS** | 60 | 59 | âœ… OK | FPS | Improving |
| **Load 100-Node Graph** | < 100ms | 85ms | âœ… OK | ms | Stable |
| **Load 500-Node Graph** | < 300ms | 250ms | âœ… OK | ms | Stable |
| **Add Node Latency** | < 4ms | 2ms | âœ… OK | ms | Stable |
| **Collab Op Propagation** | < 80ms | 60ms | âœ… OK | ms | Stable |
| **Hot Reload Roundtrip** | < 500ms | 350ms | âœ… OK | ms | Stable |
| **WebGL Runtime Start** | < 3s | 2.5s | âœ… OK | s | Stable |
| **Memory Usage (1000 nodes)** | < 100MB | 85MB | âœ… OK | MB | Stable |
| **Canvas Pan Latency** | < 16ms | 12ms | âœ… OK | ms | Stable |

---

# â­ 8. AI QA DASHBOARD â€” "WAYPOINT / LUNA QA"

**Type:** Database  
**Purpose:** Track AI/LUNA feature quality

### Database Fields

| Field | Type | Description |
|-------|------|-------------|
| **AI Feature** | Text | Feature name | - |
| **Expected** | Multi-line | Expected behavior | - |
| **Actual** | Multi-line | Actual behavior | - |
| **Pass/Fail** | Select | Test result | âœ… Pass, âŒ Fail |
| **Test Case** | Relation | Related test case | â†’ Test Cases |
| **Confidence Score** | Number | AI confidence | 0-100 |
| **Hallucination Count** | Number | Invalid outputs | - |
| **Last Tested** | Date | Last test date | - |

### AI QA Test Matrix

| AI Feature | Expected | Actual | Pass/Fail | Confidence |
|------------|----------|--------|-----------|------------|
| **Natural language â†’ Blueprint** | Valid graph structure | Valid graph, correct nodes | âœ… Pass | 85% |
| **Error Explanation** | Human-readable message | Clear, actionable message | âœ… Pass | 90% |
| **Auto-Fix Graph** | Corrections applied cleanly | Fixes applied, no breakage | âœ… Pass | 88% |
| **Suggest Node** | Relevant suggestion | Context-aware suggestions | âœ… Pass | 92% |
| **Co-Pilot Mode** | No hallucinations | Valid node connections | âœ… Pass | 87% |
| **Graph Optimization** | Improved performance | Reduced node count | ğŸ”„ Testing | - |
| **Code Comments** | Helpful comments | Clear documentation | âœ… Pass | 89% |

---

# â­ 9. DAILY QA SCRUM DASHBOARD

**Type:** Kanban Board  
**Purpose:** Daily QA task management

### Board Columns

```
Today â†’ In Review â†’ Blockers â†’ Tomorrow
```

### Task Fields

| Field | Type | Description |
|-------|------|-------------|
| **Task** | Text | Daily task description | - |
| **Priority** | Select | Task priority | High, Medium, Low |
| **Category** | Select | Task category | Testing, Bug Fix, Documentation |
| **Estimated Time** | Number | Hours to complete | - |
| **Assigned To** | Person | Team member | - |
| **Status** | Board Column | Current state | - |
| **Blocked By** | Relation | Blocking issues | â†’ QA Board |
| **Notes** | Multi-line | Additional notes | - |

---

# â­ 10. PRE-RELEASE QA GATING â€” "Alpha / Beta / Prod"

**Type:** Database  
**Purpose:** Release readiness tracking

### Database Fields

| Field | Type | Description |
|-------|------|-------------|
| **Release** | Text | Release version | v1.0.0-alpha |
| **Gate** | Select | Release gate | Alpha, Beta, RC, Production |
| **Status** | Select | Gate status | ğŸ”´ Blocked, ğŸŸ¡ In Progress, ğŸŸ¢ Pass |
| **Criteria Met** | Number | Percentage | 0-100 |
| **Blockers** | Relation | Blocking issues | â†’ QA Board |
| **Test Coverage** | Number | Coverage percentage | - |
| **Automation Coverage** | Number | Automated coverage | - |
| **P0 Bugs** | Number | Critical bugs | - |
| **P1 Bugs** | Number | Major bugs | - |
| **Visual Regressions** | Number | Chromatic failures | - |
| **Performance Issues** | Number | Performance failures | - |
| **Approved By** | Person | Release approver | - |
| **Release Date** | Date | Target release date | - |

### Release Gate Criteria

| Gate | Automation Coverage | Visual Regression | P0 Bugs | P1 Bugs | Criteria |
|------|---------------------|-------------------|---------|---------|----------|
| **Alpha** | 60%+ | Major flows tested | 0 | â‰¤5 | Major flows work |
| **Beta** | 85%+ | All critical stories green | 0 | â‰¤2 | Visual regression green |
| **RC** | 95%+ | All stories green | 0 | 0 | 0 P0 bugs |
| **Production** | 100% critical paths | 100% coverage | 0 | 0 | All gates pass |

---

# ğŸ“Š Dashboard Views & Filters

## Recommended Views

### 1. **QA Board â€” By Severity**
- Filter: `Severity = P0 OR P1`
- Sort: Severity (descending), Created (ascending)
- **Use:** Focus on critical issues

### 2. **QA Board â€” By Subsystem**
- Group by: `Subsystem`
- Filter: `Status != Done`
- **Use:** Track subsystem-specific issues

### 3. **Test Cases â€” Needs Automation**
- Filter: `Automated? = No AND Status = Ready`
- Sort: Area, Feature
- **Use:** Identify tests to automate

### 4. **Performance Dashboard â€” Degrading**
- Filter: `Trend = Degrading`
- Sort: Current vs Target (ascending)
- **Use:** Identify performance regressions

### 5. **Visual Regression â€” Failed**
- Filter: `Status = Fail`
- Sort: Last Run (descending)
- **Use:** Review visual failures

---

# ğŸ¯ Key Metrics Dashboard

## Summary Statistics

| Metric | Current | Target | Status |
|--------|---------|--------|--------|
| **Total Test Cases** | 200+ | 250+ | ğŸŸ¡ |
| **Automation Coverage** | 75% | 90% | ğŸŸ¡ |
| **Open P0 Bugs** | 0 | 0 | âœ… |
| **Open P1 Bugs** | 3 | 0 | ğŸŸ¡ |
| **Visual Regression Pass Rate** | 98% | 100% | ğŸŸ¡ |
| **Performance Pass Rate** | 95% | 100% | ğŸŸ¡ |
| **E2E Pass Rate** | 92% | 95% | ğŸŸ¡ |

---

# ğŸš€ Quick Start Guide

## Setting Up in Notion

1. **Create Database:** "WISSIL QA Board"
2. **Add Fields:** Copy fields from section 1
3. **Create Views:** Set up recommended views
4. **Create Relations:** Link to Test Cases database

## Setting Up in Linear

1. **Create Team:** "WISSIL QA"
2. **Create Projects:** "QA Cycles", "Visual Regression"
3. **Set up Labels:** QA Category, Severity, Type
4. **Create Workflows:** Match board columns

---

# ğŸ“‹ Maintenance Checklist

- [ ] Update test coverage weekly
- [ ] Review performance metrics daily
- [ ] Triage visual regressions on PR merge
- [ ] Update regression matrix when features change
- [ ] Run QA cycles before releases
- [ ] Update release gates monthly

---

**Status: Production Ready** âœ…

*Last Updated: December 2024*

